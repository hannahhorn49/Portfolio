{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Programmer: Hannah Horn\n",
    "# Class: CPSC 322, Fall 2024\n",
    "# Programming Assignment #4\n",
    "# Last Modified: 10/18/2024\n",
    "# I did not attempt the bonus.\n",
    "# \n",
    "# Description: This program implements three different classifiers (Linear, KNN, and Dummy)\n",
    "# and compares the accuracy of these classifiers based on the five random testing instances. \n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "import random\n",
    "from mypytable import MyPyTable\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "# import mysklearn.mypytable\n",
    "# importlib.reload(mysklearn.mypytable)\n",
    "# from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MySimpleLinearRegressionClassifier,\\\n",
    "    MyKNeighborsClassifier,\\\n",
    "    MyDummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 ðŸš— Auto Classification ðŸš—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Train/Test Sets: Random Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, auto-data-remove-NA copy.txt originally had 260 instances, after dropping the five random rows to use for the test set, the dataset stored in table now has 255 rows which will make up the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = myutils.load_and_prepare_train_data(\"auto-data-remove-NA copy.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train/Test Sets: Random Instances and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to set up the training data. You need to get the relevant data and split according to X and y values. Since the get_column function returns a 1D list and the fit method expects a 2D list we need to reshape the X_values to this format. We then fit the linear classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the trainign set\n",
    "X_values = table.get_column(\"weight\")\n",
    "y_values = table.get_column(\"mpg\")\n",
    "\n",
    "# since the get_column returns a 1D list for both values, the fit method needs to accept a 2D list\n",
    "X_values_reshaped = []\n",
    "for weight in X_values:\n",
    "    X_values_reshaped.append([weight])\n",
    "\n",
    "# create instance of the MySimpleLinearRegressionClassifier\n",
    "linear_classifier = MySimpleLinearRegressionClassifier(discretizer = myutils.doe_rating_assign)\n",
    "\n",
    "# fit the classifier (understand the relationship between features and target values)\n",
    "linear_classifier.fit(X_values_reshaped, y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in this process is to set up the testing data. We first verify the five random indexes we are working with and reload the original dataset into a new MyPyTable object so we have access to the original indexes that were dropped from the training dataset. Similar to the training data, we get the weight column and convert it to a 2D list format. Next, we need to map the mpg column to the corresponding DOE ratings so we can compare the actual ratings versus the classifiers predicted ratings. Finally, after calling the predict method, we calculate and print out the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: these is X_test_indexes: [154, 164, 38, 237, 241]\n",
      "These are the DOE rating for the test mpg instances:  [3, 4, 7, 5, 4]\n",
      "These are the predicted DOE mpg ratings based on the test weights: [2, 4, 7, 5, 4]\n",
      "This is the number of correct predictions: 4\n",
      "This is the accuracy of the classifier based on the test instances, 80.0%\n"
     ]
    }
   ],
   "source": [
    "X_test_indexes = myutils.select_random_instances_from_dataset(table.data, 5)\n",
    "print(\"DEBUG: these is X_test_indexes:\", X_test_indexes)\n",
    "\n",
    "original_data = myutils.load_and_prepare_test_data(\"auto-data-remove-NA copy.txt\")\n",
    "original_weight = original_data.get_column(\"weight\")\n",
    "\n",
    "test_weights = []\n",
    "for index in X_test_indexes:\n",
    "    weight = original_weight[index]\n",
    "    test_weights.append([weight]) # make sure append in 2D list format\n",
    "\n",
    "original_mpg = original_data.get_column(\"mpg\")\n",
    "\n",
    "test_doe_mpg_rating = []\n",
    "for index in X_test_indexes:\n",
    "    mpg = original_mpg[index]\n",
    "    rating = myutils.doe_rating_assign(mpg)\n",
    "    test_doe_mpg_rating.append(rating)\n",
    "print(\"These are the DOE rating for the test mpg instances: \", test_doe_mpg_rating)\n",
    "\n",
    "model_predictions = linear_classifier.predict(test_weights)\n",
    "print(\"These are the predicted DOE mpg ratings based on the test weights:\", model_predictions)\n",
    "\n",
    "# call calculate accuracy function\n",
    "myutils.calculate_accuracy(model_predictions, test_doe_mpg_rating, X_test_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Train/Test Sets: Random Instances and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for this classifier is to get the relevant columns (cylinder, weight, acceleration) that will be used to predict the DOE mpg ratings. We then have to normalize the three attribute values and combine these new values into a 2D list. We extract the target(y_value) and get the DOE mpg ratings for each instance. Finally, we fit the classifier with these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns \n",
    "cylinder_values = table.get_column(\"cylinders\")\n",
    "weight_values = table.get_column(\"weight\")\n",
    "acceleration_values = table.get_column(\"acceleration\")\n",
    "\n",
    "# normalize each feature\n",
    "normalized_cylinder = myutils.normalize_train_attribute(cylinder_values)\n",
    "normalized_weight = myutils.normalize_train_attribute(weight_values)\n",
    "normalized_acceleration = myutils.normalize_train_attribute(acceleration_values)\n",
    "\n",
    "# combine normalized attributes into a 2D list\n",
    "combined_X_train = myutils.combine_normalized_attributes(normalized_cylinder, normalized_weight, normalized_acceleration)\n",
    "\n",
    "# extract target (y_value) labels (DOE mpg ratings) that correspond to each instance\n",
    "mpg_values = table.get_column(\"mpg\")\n",
    "y_train = []\n",
    "for value in mpg_values:\n",
    "    rating = myutils.DOE_rating_assign(value)\n",
    "    y_train.append(rating)\n",
    "\n",
    "# initialize and fit classifier\n",
    "knn_classifier = MyKNeighborsClassifier()\n",
    "knn_classifier.fit(combined_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of this process is to set up the testing data. We first reload the original data and go through a similar process as the training data (normalization and combining into a 2D list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: this is X_test_indexes: [154, 164, 38, 237, 241]\n"
     ]
    }
   ],
   "source": [
    "original_table = myutils.load_and_prepare_test_data(\"auto-data-remove-NA copy.txt\")\n",
    "X_test_indexes = myutils.select_random_instances_from_dataset(table.data, 5)\n",
    "print(\"DEBUG: this is X_test_indexes:\", X_test_indexes)\n",
    "\n",
    "# get columns\n",
    "original_cylinder = original_table.get_column(\"cylinders\")\n",
    "original_weight = original_table.get_column(\"weight\")\n",
    "original_acceleration = original_table.get_column(\"acceleration\")\n",
    "\n",
    "# normalize each attribute\n",
    "normalized_cylinder2 = myutils.normalize_test_attribute(original_cylinder, X_test_indexes)\n",
    "normalized_weight2 = myutils.normalize_test_attribute(original_weight, X_test_indexes)\n",
    "normalized_acceleration2 = myutils.normalize_test_attribute(original_acceleration, X_test_indexes)\n",
    "\n",
    "# combine normalized attributes into a 2D list\n",
    "combined_X_test = myutils.combine_normalized_attributes(normalized_cylinder2, normalized_weight2, normalized_acceleration2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of this process is to get the five nearest neighbors and call the predict method of the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the predicted DOE mpg ratings from knn: [3, 4, 7, 5, 4]\n",
      "this is the actual doe rating for each mpg in the test index: [3, 4, 7, 5, 4]\n",
      "this is the number of correct predictions: 5\n",
      "This is the accuracy of the classifier based on the test instances, 100.0%\n"
     ]
    }
   ],
   "source": [
    "knn_classifier.kneighbors(combined_X_test, n_neighbors = 5)\n",
    "predicted_ratings = knn_classifier.predict(combined_X_test)\n",
    "print(\"These are the predicted DOE mpg ratings from knn:\", predicted_ratings)\n",
    "\n",
    "# get actual DOE mpg rating for test indexes\n",
    "original_mpg = original_table.get_column(\"mpg\")\n",
    "test_actual_doe_rating_mpg = []\n",
    "for index in X_test_indexes:\n",
    "    mpg_value = original_mpg[index]\n",
    "    rating = myutils.DOE_rating_assign(mpg_value)\n",
    "    test_actual_doe_rating_mpg.append(rating)\n",
    "print(\"this is the actual doe rating for each mpg in the test index:\", test_actual_doe_rating_mpg)\n",
    "\n",
    "myutils.calculate_accuracy(predicted_ratings, test_actual_doe_rating_mpg, X_test_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Train/Test Sets: Random Instances and Dummy Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Dummy Classifier, we want to predict the DOE mpg rating. We first set up the training data by calling the function that loads the file into a new MyPyTable object and drops the testing rows from the data. We then create an instance of the class and fit with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = myutils.load_and_prepare_train_data(\"auto-data-remove-NA copy.txt\")\n",
    "\n",
    "# split the dataset into features (X) and target values (y)\n",
    "X_values = table.get_column(\"mpg\")\n",
    "\n",
    "y_values = []\n",
    "for value in X_values:\n",
    "    rating = myutils.DOE_rating_assign(value)\n",
    "    y_values.append(rating)\n",
    "\n",
    "# create instance of MyDummyClassifier\n",
    "dummy_classifier = MyDummyClassifier()\n",
    "# fit the classifier (understand the relationship between features and target values)\n",
    "dummy_classifier.fit(X_values, y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up the testing data by reloading the original data into a new MyPyTable object and extracting the testing indexes. We then get the mpg values and call the predict method on those values. We then get the actual rating for the test mpg values and calculate the accuracy of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is X_test_indexes: [154, 164, 38, 237, 241]\n",
      "this is after getting mpg for test index:  [16.0, 18.0, 30.0, 20.6, 18.2]\n",
      "These are the predicted DOE mpg ratings based on the test mpg values: [4, 4, 4, 4, 4]\n",
      "this is the doe rating for each mpg in test index: [3, 4, 7, 5, 4]\n",
      "this is the number of correct predictions: 2\n",
      "This is the accuracy of the classifier based on the test instances, 40.0%\n"
     ]
    }
   ],
   "source": [
    "data = myutils.load_and_prepare_test_data(\"auto-data-remove-NA copy.txt\")\n",
    "X_test_indexes = myutils.select_random_instances_from_dataset(table.data, 5)\n",
    "print(\"this is X_test_indexes:\", X_test_indexes)\n",
    "\n",
    "original_mpg = original_table.get_column(\"mpg\")\n",
    "\n",
    "# now get the actual mpg value for the test index\n",
    "test_mpg = []\n",
    "for index in X_test_indexes:\n",
    "    mpg = original_mpg[index]\n",
    "    test_mpg.append(mpg)\n",
    "print(\"this is after getting mpg for test index: \", test_mpg)\n",
    "\n",
    "model_predictions = dummy_classifier.predict(test_mpg)\n",
    "print(\"These are the predicted DOE mpg ratings based on the test mpg values:\", model_predictions)\n",
    "\n",
    "# now get actual rating for mpg value at test index\n",
    "test_rating = []\n",
    "for index in test_mpg:\n",
    "    rating = myutils.DOE_rating_assign(index)\n",
    "    test_rating.append(rating)\n",
    "print(\"this is the doe rating for each mpg in test index:\", test_rating)\n",
    "\n",
    "myutils.calculate_accuracy(model_predictions, test_rating, X_test_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Classifier Comparison: Linear Regression vs kNN vs Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now implemented the three different classifiers on the same five random testing instances from the dataset and calculated their accuracy. Here are the results from the first run (random seed = 49):\n",
    "1. `Linear Regression Classifier:` This classifier successfully predicted four out of the five instances, giving it a **80%** accuracy rating. \n",
    "\n",
    "2. `KNN Classifier:` This classifier successfully predicted all five of the testing instances, giving it a **100%** accuracy rating. \n",
    "\n",
    "3. `Dummy Classifier:` This classifier predicted just one out of the five instances, giving it a **20%** accuracy rating. \n",
    "\n",
    "Based on the accuracy rating, while the Linear Regression Classifier performed well, the KNN Classifier could not be beat by getting a perfect 5/5 score. It doesn't come as a suprise that the Dummy Classifier performed the worse as it just predicts the most common rating. \n",
    "\n",
    "I then adjusted the random seed and re ran each of the classifiers to see how the results would vary. Here are the results from first five runs:\n",
    "1. Random Seed = 12\n",
    "*   `Linear Regression Classifier:` 80% accuracy\n",
    "*   `KNN Classifier:` 80% accuracy\n",
    "*   `Dummy Classifier:` 0% accuracy\n",
    "\n",
    "2. Random Seed = 1\n",
    "*   `Linear Regression Classifier:` 40% accuracy\n",
    "*   `KNN Classifier:` 100% accuracy\n",
    "*   `Dummy Classifier:` 40% accuracy\n",
    "\n",
    "3. Random Seed = 33\n",
    "*   `Linear Regression Classifier:` 80% accuracy\n",
    "*   `KNN Classifier:` 100% accuracy\n",
    "*   `Dummy Classifier:` 20% accuracy\n",
    "\n",
    "4. Random Seed = 76\n",
    "*   `Linear Regression Classifier:` 60% accuracy\n",
    "*   `KNN Classifier:` 60% accuracy\n",
    "*   `Dummy Classifier:` 0% accuracy\n",
    "\n",
    "5. Random Seed = 147\n",
    "*   `Linear Regression Classifier:` 80% accuracy\n",
    "*   `KNN Classifier:` 100% accuracy\n",
    "*   `Dummy Classifier:` 40% accuracy\n",
    "\n",
    "As you can see, overall **KNN remained the most accurate classifier**, the dummy had the worst score, and the linear classifier stayed relatively consistent across the runs. \n",
    "\n",
    "I think that we could improve the reliability of our comparisons by making the testing data more representative of the dataset rather than just a completely random sample of the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
